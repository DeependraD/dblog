---
title: 'Stability analysis: how to guide'
author: Deependra Dhakal
date: '2018-08-14'
slug: stability-analysis-how-to-guide
math: true
bibliography: ["../bib/2018-08-14-stability-analysis-how-to-guide.bib"]
link-citations: true
categories:
  - Plant Breeding
  - R
tags:
  - agriculture
  - R
output:
  blogdown::html_page:
    toc: true
header:
  caption: ''
  image: ''
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(tidy = TRUE, cache = TRUE, 
                      echo = FALSE, 
                      tidy.opts = list(width.cutoff=50), 
                      eval = TRUE, 
                      fig.show = "hold", fig.align = "center", fig.width = 6,
                      fig.asp = 0.8, message = FALSE, warning = FALSE)
options(knitr.kable.NA = "", digits = 3)
```

# Meaning of stability 

Comparison of treatments may also imply cross comparison of their stability across multiple environments, especially when a study constitutes a series of trials that are each conducted at different locations and/or at different periods in time (henceforth referred to as MET; **M**ulti-**E**nvironment **T**rial). Several situations exist where only mean based performance analysis are regarded inconclusive. 

For example, in varietal release process the authorizing body seeks record of consistent trait performace of certain crop genotype. The imperative is: a variety needs to be stably exhibit it's characters in the proposed domain of cultivation, which generally is a wide area, throughout a long duration of cultivation cycles. This pre-condition of stable character inheritance is more relevant to crops constituting a homogenous and homozygous population. Either of the location, time period or combination of both, more commonly framed as year in field researches, could be assumed to present an unique environment that treatment entries are tested in. Thus, for results to be widely applicable, performance measures across environments should be more or less stable. To the contrary, the concept of utilizing differential character expression across different environments is often explored when interaction between genotypes and environments result in more desirable character.

In MET trials, it is also of interest whether the same treatments perform well or poorly in all locations, or are there as-yet-unknown subpopulations such that some treatments perform optimally at certain types of locations whereas other treatments are better suited for other locations[@littell2007sas]. By assessing the simple effects of treatments at each location using the BLUPs demonstrated in this example, the stability issue can be addressed using mixed model methods.

# Introduction

GE has been a research focus among biometricians and quantitative geneticists since the early 1900s. With the notion that GE is undesirable and/or that it confounds genotype evaluation, much work has been devoted to developing stability indices to quantify and select against GE. Many stability indices have been proposed, as reviewed in Lin and Binns (1994) and more recently in Yan and Kang (2003). Several books and symposium proceedings have been published to document the advances in the study of GE (Byth and Montgomery1981; Kang, 1990, 2003; Gauch 1992; Imrie and Hacker 1993; Kang and Gauch 1996; Cooper and Hammer 1996) and most earlier research on GE can be traced from these publications.[copied]

Two concepts exist that aim to explain the stability -- static/biological stability and dynamic/agronomic stability. The concept of static stability maintains that the genotypic response of a trait remains unchanged over environment, i.e. a genotype has equally same response across all environments. This concept is defines stability in absolute stringent terms, which actually is never the case when dealing with natural components.The other concept, dynamic stability, attempts to associate stability with predictive performance. It highlights the importance of statistical agreement between the predicted performance and the observed performance.

# Principles of Biplot analysis

A biplot is a scatter plot that approximates and graphically displays a two-way table by both its row and column factors such that relationships among the row factors, relationships among the column factors, and the underlying interactions between the row and column factors can be visualized simultaneously. Since its first report by Gabriel (1971), biplots have been used in visual data analysis by scientists of all disciplines, from economics, sociology, business, medicine, to ecology, genetics, and agronomy. The first application of biplots to agricultural data analysis was Bradu and Gabriel (1978), who used data from a cotton performance trial to illustrate the diagnostic role of biplots for model selection.

A common misconception is that biplot analysis is equivalent to principle component analysis (PCA). While both biplot analysis and PCA use Singular Value Decomposition (SVD) (Pearson 1901) as a key mathematical technique, biplot analysis is a fuller use of SVD to allow two interacting factors to be visualized simultaneously.

## Biplot and its Inner-product Property

Mathematically, a biplot may be regarded as a graphical display of matrix multiplication. Given a matrix $G$ with $m$ rows and $r$ columns, and a matrix $E$ with $r$ rows and $n$ columns, they can be multiplied to give a third matrix $P$ with $m$ rows and $n$ columns. If **r = 2**, then matrix $G$ can be displayed as $m$ points in a 2-D plot, with the 1st column as the abscissa ($x$-axis) and 2nd column the ordinate ($y$-axis). Similarly, matrix $E$ can be displayed as $n$ points in a 2-D plot, with the 1st row as the abscissa and 2nd row the ordinate. A 2-D biplot is formed if the two plots are superimposed, which would contain $m + n$ points. An interesting property of this biplot is that it not only displays matrices $G$ and $E$, but also implicitly displays the $m \times n$ values of matrix $P$, because each element of $P$ can be visualized as:

$$
p_{ij} = x_ix^\prime_j + y_iy^\prime_j = \vec{g_i}\vec{e_i} = |g_i||e_j|\cos\theta_{ij}
$$

where $(x_i, y_i)$ are the coordinates for row $i$ and $(x\prime_j, y\prime_j)$ are the coordinates for column j. $\vec{g_i}$ is the vector for row $i$ and $\vec{e_i}$ is the vector for column $j$. $|g_i|$ is the vector length for row i and $|e_j|$ is the vector length for column j. $\theta_{ij}$ is the angle between the vectors of row $i$ and column $j$.

The founder of biplot (Gabriel 1971) summarizes biplot analysis as any two-way table can be graphically analyzed using a 2-D biplot as soon as it can be sufficiently approximated by a rank-2 (i.e., $r$ = 2) matrix.

**Example: 1**

Let us consider two matrices, matrix $G$ and matrix $E$ as shown below:

$$
G = \left[
\begin{matrix}
2 & 4 \\
2 & 3 \\
4 & -3 \\
-2 & -1 \\
\end{matrix}
\right]
;\ 
E = \left[
\begin{matrix}
6 & 5 & -4 \\
3 & -1 & -2 \\
\end{matrix}
\right]
$$

```{r example1-matrices, echo=FALSE}
G <- matrix(c(2, 4, 2, 3, 4, -3, -2, -1), nrow = 4, byrow = TRUE)
E <- matrix(c(6, 3, 5, -1, -4, -2), ncol = 3, byrow = FALSE)

matrix_prod <- G %*% E
```

Now by cross multiplying (vector multiplication) of $G$ and $E$, we get $P$ matrix:

$$
P = 
\left[
\begin{matrix}
24 & 6 & -16 \\
21 & 7 & -14 \\
15 & 23 & -10 \\
-15 & -9 & 10 \\
\end{matrix}
\right]
$$

The matrix is a "rank 2" matrix. Taking a graphical approach, we can visualize the above two matrices; we can overlay the plottings of matrices in a way stated above to obtain a graph of $m+n$ points where, $m$ = number of rows in $G$ matrix and $n$ = number of columns in $E$ matrix.

```{r example-matrices-plot, fig.cap="Biplot of G and E matrices with m+n=7 points"}
G_df <- G %>% as_tibble()
E_df <- E %>% t() %>% as_tibble()

ge_m <- ggplot() + 
  geom_point(data = G_df, aes(x = V1, y = V2), 
             size = 4, color = "turquoise", shape = 15) +
  geom_point(data = E_df, aes(x = V1, y = V2), 
             size = 4, color = "tomato", shape = 15) +
  geom_text(data = G_df, aes(x = V1, y = V2, label = paste("G[R", 1:4, "]", sep = "")), 
            color = "turquoise", nudge_x = 0.5, check_overlap = TRUE, parse = TRUE) +
  geom_text(data = E_df, aes(x = V1, y = V2, label = paste("E[C", 1:3, "]", sep = "")), 
            color = "tomato", nudge_x = 0.5, check_overlap = TRUE, parse = TRUE) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  labs(x = "X", y = "Y") +
  theme_minimal()
ge_m
```

The proof about approximation of $P$ matrix can be shown geometrically, i.e.:

$$
P_{ij} = \vec{R_i}cos\alpha_{ij}\vec{C_j};\\
\vec{R_i} = \sqrt{x^2_{R_i} + y^2_{R_i}},~\vec{C_j} = \sqrt{x^2_{C_j} + y^2_{C_j}}
$$

First, to determine the segment length, we compute the distance between the corresponding point and the centre.

```{r segment-length}
Ri_vec <- sqrt(G[,1]^2 + G[,2]^2)
Cj_vec <- sqrt(E[1,]^2 + E[2,]^2)
Ri_vec
Cj_vec
```


Calculate clockwise angle between row and column segments connected by the origin.

```{r segment-angle-theta}
theta_mat <- map_dfr(c(1:4), 
        function(Ri){
          map_dfc(c(1:3), 
                  function(Cj){
                    acos((E[,Cj]%*%G[Ri,])/(sqrt(E[,Cj]%*%E[,Cj])*sqrt(G[Ri,]%*%G[Ri,])))*180/pi
                  }
          )
        }
)

theta_mat <- janitor::clean_names(theta_mat)

```

As an example, two segments: G_R1 and E_C1, are joined illustrating the angle between them.

```{r segment-r1c1-angle}
require(ggforce)
# optimal value of radius of circle with radius (0, 0) is 
# best approximated based upon the average of the lengths of the segments
mean_length_segments <- mean(c(Ri_vec, Cj_vec))
r <- mean_length_segments*0.15

# indicating centre of circle as (0, 0)
a <- b <- 0

# calculate theta (anticlockwise) for each line segment
theta_GR1 <- acos(G_df$V1[1]/G_df$V2[1])*180/pi
theta_EC1 <- asin(E_df$V2[1]/E_df$V1[1])*180/pi

# point (x_1, y_1)
x_1 = a + r * cos(theta_GR1*pi/180)
y_1 = b + r * sin(theta_GR1*pi/180)

# point (x_2, y_2)
x_2 = a + r * cos(theta_EC1*pi/180)
y_2 = a + r * sin(theta_EC1*pi/180)

# here, (x_1, y_1) and (x_2, y_2) are points on the circumference of circle
# r is the radius of the circle
# (a,b) is the center of the circle
# (x,y) is the point on the circumference
# theta_EC1 and theta_GR1 are the angle in degrees
# radian = degree * pi/180

ge_m1 <- ge_m +
  # geom_segment(data = G_df, aes(x = 0, xend = V1, y = 0, yend = V2), 
  #              arrow = arrow(), colour = "#FF3EFF", size = 1.25) +
  # geom_segment(data = E_df, aes(x = 0, xend = V1, y = 0, yend = V2),
  #              arrow = arrow(), colour = "#30B48D", size = 1.0)
  geom_segment(aes(x = 0, xend = c(G_df$V1[1]), 
                   y = 0, yend = c(G_df$V2[1])), 
               arrow = arrow(), colour = "#FF3EFF", linewidth = 1.25) +
  geom_segment(aes(x = 0, xend = c(E_df$V1[1]), 
                   y = 0, yend = c(E_df$V2[1])),
               arrow = arrow(), colour = "#30B48D", linewidth = 1.0)

ge_m1 + coord_equal(xlim = c(-6, 6), ylim = c(-6, 6))
# ge_m1 + 
#   coord_equal(xlim = c(-6, 6), ylim = c(-6, 6)) +
#   geom_arc(aes(x0 = 0, y0 = 0, r = r, # to c1
#                start = (2*pi*r/360)*asin(G_df$V1[1]/G_df$V2[1])*180/pi,
#                end = (2*pi*r/360)*((asin(G_df$V1[1]/G_df$V2[1])*180/pi)+theta_mat$V1[1])))
```

From the above equation, first element of matrix $P$ ($P_{ij}$) is:

\begin{equation}
\begin{split}
P_{11} & = \vec{R_1}cos\alpha_{11}\vec{C_1} \\
& = 4.46\ cos(36.9)\ 6.71 \\
& = 24
\end{split}
\end{equation}

Similarly, to obtain the column vector $P_{i1}$, we have following four elements resulting from the vector product.

```{r vector-product}
map_dbl(c(1:4), ~ Ri_vec[.x] * cos(theta_mat$x1[.x]*pi/180) * Cj_vec[1])
```

Kronecker solution to matrix binding

```{r kronecker-product}
RC_kro <- G %x% rep(1, 3) %>% 
  cbind(rep(1, 4) %x% t(E))
```


## Singular value decomposition and partitioning

## Column-metric preserving and associated interpretations

## Row-metric preserving and associated interpretations

## Data centering prior to SVD

## Data scaling prior to SVD

# Four questions to be asked before trying to interpret a biplot

1. What is the model on which the biplot is generated?
2. How are the singular values partitioned?
3. What is the goodness of fit of the biplot for the table that is to be visualized?
4. Are the axes drawn to scale?

# Simplest case of biplot analysis

```{r simulated-data, eval=FALSE}
simdata <- tribble(
  ~VarA, ~VarB, ~VarC,
  6, 3, 7,
  8, 6, 7,
  9, 4, 2
)

s_sim <- simdata %>% 
  scale(center = T, scale = F) %>% 
  svd()

s_sim$v %*% diag(s_sim$d)
s_sim$u
```

# Multienvironment trial data

```{r met-data-import, eval=FALSE}
wheat_met <- readxl::read_xlsx(here::here("content", "blog", "data", "soybean_data_multienv.xlsx"))
wheat_met %>% 
  head(n=10) %>% 
  knitr::kable(caption = "Yield trial of soybean genotypes in multiple environments over years.") %>% 
  kableExtra::kable_styling(latex_options = c("striped", "scale_down"), position = "center")

```

# AMMI Analysis

```{r rewrite-ammi-function, eval=FALSE}
function (dataframe, environment, genotype, replication, yvar) 
{
  dataframe <- data.frame(environment = dataframe[, environment], 
                          genotype = dataframe[, genotype], replication = dataframe[, 
                                                                                    replication], Y = dataframe[, yvar])
  yvar <- yvar
  cat("\nAMMI Analysis for variable: ", yvar, "\n")
  cat("\n............................\n")
  dataframe$environment <- as.factor(dataframe$environment)
  dataframe$genotype <- as.factor(dataframe$genotype)
  dataframe$replication <- as.factor(dataframe$replication)
  dataframe$Y <- dataframe$Y
  nenv <- length(unique(dataframe$environment))
  ngen <- length(unique(dataframe$genotype))
  nrep <- length(unique(replication))
  minM <- min(ngen, nenv)
  model <- aov(Y ~ environment + replication %in% environment + 
                 genotype + environment:genotype, dataframe)
  anmm <- anova(model)
  newm <- anmm[2, ]
  anmm[2, ] <- anmm[3, ]
  anmm[3, ] <- newm
  row.names(anmm)[2] <- "replication(environment )"
  row.names(anmm)[3] <- "genotype"
  anmm[1, 4] <- anmm[1, 3]/anmm[2, 3]
  anmm[1, 5] <- 1 - pf(anmm[1, 4], anmm[1, 1], anmm[2, 1])
  print(anmm)
  DFE <- df.residual(model)
  MSE <- deviance(model)/DFE
  medy <- mean(dataframe$Y, na.rm = TRUE)
  CV = sqrt(MSE) * 100/medy
  errorlist <- list(DFE, MSE, medy, CV)
  df1 <- data.frame(environment = dataframe$environment, genotype = dataframe$genotype, 
                    dataframe$Y)
  names(df1) <- c("environment", "genotype", "Y")
  avdm0 <- tapply(df1$Y, df1[, c("genotype", "environment")], 
                  mean)
  cat("\nMeans: ", yvar, "\n")
  print(round(avdm0, 2))
  require(reshape)
  avdm <- melt(avdm0, id = c("environment ", "genotype"))
  V1 <- avdm[, 2]
  v2 <- avdm[, 1]
  v3 <- avdm[, 3]
  model2 <- lm(v3 ~ V1 + v2, avdm)
  for (i in 1:length(v3)) {
    if (is.na(v3[i])) 
      v3[i] <- predict(model2, data.frame(V1 = avdm[i, 
                                                    1], v2 = avdm[i, 2]))
  }
  avdm <- data.frame(environment = V1, genotype = v2, Y = v3)
  model1 <- lm(Y ~ environment + genotype, data = avdm)
  residual <- model1$residuals
  avdm <- data.frame(avdm, RESIDUAL = residual)
  mlabel <- names(avdm)
  names(avdm) <- c(mlabel[1:2], yvar, mlabel[4])
  resouts <- avdm[order(avdm[, 1], avdm[, 2]), ]
  res22 <- aggregate(resouts[, 4], by = list(resouts[, 2], 
                                             resouts[, 1]), FUN = sum)
  names(res22) <- c("genotype", "environment", "gei")
  res3 <- aggregate(gei ~ genotype, res22, "c")
  res23 <- as.matrix(res3[, -1])
  mdout <- by(resouts[, 3], resouts[, c(2, 1)], function(x) sum(x, 
                                                                na.rm = TRUE))
  sdc <- svd(res23)
  U <- sdc$u
  L <- sdc$d
  V <- sdc$v
  L <- L[1:minM]
  SS <- (L^2) * nrep
  a.sumsq <- sum(SS)
  percent <- round(((1/a.sumsq) * SS) * 100, 1)
  MINM <- min(ngen, nenv)
  acum <- MSami <- F.ami <- f.prob <- DFami <- rep(0, minM)
  Acol1 <- 0
  for (i in 1:minM) {
    DF <- (ngen - 1) + (nenv - 1) - (2 * i - 1)
    if (DF <= 0) 
      break
    DFami[i] <- DF
    Acol1 <- Acol1 + percent[i]
    acum[i] <- acum[i] + Acol1
    MSami[i] <- SS[i]/DFami[i]
    F.ami[i] <- round(MSami[i]/MSE, 2)
    f.prob[i] <- round(1 - pf(F.ami[i], DFami[i], DFE), 4)
  }
  ammi.ss <- data.frame(percent, cumulative = acum, Df = DFami, 
                        `Sum Sq` = round(SS, 1), `Mean Sq` = round(MSami, 1), 
                        `F value` = F.ami, prob = round(f.prob, 4))
  nssammi <- nrow(ammi.ss)
  ammi.ss <- ammi.ss[ammi.ss$Df > 0, ]
  row.names(ammi.ss) <- paste("PCA", 1:nrow(ammi.ss), sep = "")
  cat("\nAMMI Analysis Results per PCA axis \n")
  print(ammi.ss)
  sql <- sqrt(diag(L))
  regscr <- U %*% sql
  scoree1 <- V %*% sql
  SCORES <- rbind(regscr, scoree1)
  colnames(SCORES) <- paste("PC", 1:nssammi, sep = "")
  MSscoree1 <- SCORES[1:ngen, ]
  NSCORES <- SCORES[(ngen + 1):(ngen + nenv), ]
  gen.m <- data.frame(category = "genotype", Y = apply(mdout, 
                                                       1, mean), MSscoree1)
  m.env <- data.frame(category = "environment", Y = apply(mdout, 
                                                          2, mean), NSCORES)
  scrs.plot <- rbind(gen.m, m.env)
  scrs.plot <- scrs.plot[, 1:(nrow(ammi.ss) + 2)]
  mlabel <- names(scrs.plot)
  names(scrs.plot) <- c(mlabel[1], yvar, mlabel[c(-1, -2)])
  row.names(scrs.plot) <- c(row.names(gen.m), row.names(m.env))
  perC <- ammi.ss[, 1]
  return(list(means = avdm0, anova = anmm, errorlist = errorlist, 
              genotype.by.env = res22, resouts = resouts, analysis = ammi.ss, 
              means = avdm, pc.scrs = scrs.plot, percentAxis = perC, 
              sdc = sdc))
}
```


# References
